{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2542f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from openpyxl import load_workbook\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf08631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 80 barcodes ‚úÖ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# READ EXCEL\n",
    "# ==============================\n",
    "wb = load_workbook(\"data.xlsx\")\n",
    "sheet = wb.active\n",
    "\n",
    "barcodes = []\n",
    "\n",
    "for row in sheet.iter_rows(min_row=3, values_only=True):\n",
    "    code = row[0]\n",
    "    if code and str(code).strip():\n",
    "        barcodes.append(str(code).strip())\n",
    "\n",
    "print(f\"Loaded {len(barcodes)} barcodes ‚úÖ\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d79d90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# DRIVER SETUP\n",
    "# ==============================\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "driver = uc.Chrome(options=options)\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "cookie_handled = False\n",
    "all_product_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da2b039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting to process all barcodes...\n",
      "\n",
      "[1/80] Processing barcode: 34356790304 SK\n",
      "============================================================\n",
      "‚úÖ Cookies accepted\n",
      "\n",
      "   ‚úÖ Found first product for barcode: 34356790304 SK\n",
      "\n",
      "      Scraping: https://www.autodoc.parts/ridex/8095160\n",
      "   ‚úÖ Product scraped: RIDEX 407W0062 Brake pad wear sensor\n",
      "Rear Axle\n",
      "   üíæ Images: 4 downloaded\n",
      "\n",
      "‚úÖ Completed barcode 34356790304 SK\n",
      "\n",
      "============================================================\n",
      "\n",
      "[2/80] Processing barcode: 34116769951\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=60960): Max retries exceeded with url: /session/e2d8f8f3da831bbae7a2390ab610e460/url (Caused by NewConnectionError(\"HTTPConnection(host='localhost', port=60960): Failed to establish a new connection: [Errno 61] Connection refused\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/connection.py:204\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/util/connection.py:85\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNewConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:493\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/connection.py:500\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28mself\u001b[39m.putheader(header, value)\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/http/client.py:1353\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1352\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1353\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/http/client.py:1113\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1113\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1116\u001b[39m \n\u001b[32m   1117\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/http/client.py:1057\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/connection.py:331\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m    333\u001b[39m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/connection.py:219\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[32m    220\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    221\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    223\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n",
      "\u001b[31mNewConnectionError\u001b[39m: HTTPConnection(host='localhost', port=60960): Failed to establish a new connection: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 220\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m    219\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://www.autodoc.parts/search?keyword=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m wait.until(EC.presence_of_element_located((By.TAG_NAME, \u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m)))\n\u001b[32m    223\u001b[39m handle_cookies()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/undetected_chromedriver/__init__.py:665\u001b[39m, in \u001b[36mChrome.get\u001b[39m\u001b[34m(self, url)\u001b[39m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url):\n\u001b[32m    663\u001b[39m     \u001b[38;5;66;03m# if self._get_cdc_props():\u001b[39;00m\n\u001b[32m    664\u001b[39m     \u001b[38;5;66;03m#     self._hook_remove_cdc_props()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/selenium/webdriver/remote/webdriver.py:356\u001b[39m, in \u001b[36mWebDriver.get\u001b[39m\u001b[34m(self, url)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    355\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/selenium/webdriver/remote/webdriver.py:345\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m    343\u001b[39m         params[\u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.session_id\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcommand_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m    347\u001b[39m     \u001b[38;5;28mself\u001b[39m.error_handler.check_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/selenium/webdriver/remote/remote_connection.py:302\u001b[39m, in \u001b[36mRemoteConnection.execute\u001b[39m\u001b[34m(self, command, params)\u001b[39m\n\u001b[32m    300\u001b[39m trimmed = \u001b[38;5;28mself\u001b[39m._trim_large_entries(params)\n\u001b[32m    301\u001b[39m LOGGER.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, command_info[\u001b[32m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/selenium/webdriver/remote/remote_connection.py:322\u001b[39m, in \u001b[36mRemoteConnection._request\u001b[39m\u001b[34m(self, method, url, body)\u001b[39m\n\u001b[32m    319\u001b[39m     body = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keep_alive:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     statuscode = response.status\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/_request_methods.py:143\u001b[39m, in \u001b[36mRequestMethods.request\u001b[39m\u001b[34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request_encode_url(\n\u001b[32m    136\u001b[39m         method,\n\u001b[32m    137\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m         **urlopen_kw,\n\u001b[32m    141\u001b[39m     )\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43murlopen_kw\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/_request_methods.py:278\u001b[39m, in \u001b[36mRequestMethods.request_encode_body\u001b[39m\u001b[34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[39m\n\u001b[32m    274\u001b[39m     extra_kw[\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m].setdefault(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m, content_type)\n\u001b[32m    276\u001b[39m extra_kw.update(urlopen_kw)\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/poolmanager.py:457\u001b[39m, in \u001b[36mPoolManager.urlopen\u001b[39m\u001b[34m(self, method, url, redirect, **kw)\u001b[39m\n\u001b[32m    455\u001b[39m     response = conn.urlopen(method, url, **kw)\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_e, (\u001b[38;5;167;01mOSError\u001b[39;00m, HTTPException)):\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n\u001b[32m    846\u001b[39m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VSCode/Python/CarPartScrapper/.venv/lib/python3.14/site-packages/urllib3/util/retry.py:535\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_retry.is_exhausted():\n\u001b[32m    534\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    537\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPConnectionPool(host='localhost', port=60960): Max retries exceeded with url: /session/e2d8f8f3da831bbae7a2390ab610e460/url (Caused by NewConnectionError(\"HTTPConnection(host='localhost', port=60960): Failed to establish a new connection: [Errno 61] Connection refused\"))"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# FUNCTION: Handle cookies\n",
    "# ==============================\n",
    "def handle_cookies():\n",
    "    global cookie_handled\n",
    "    if not cookie_handled:\n",
    "        try:\n",
    "            cookie_btn = wait.until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    (By.CSS_SELECTOR, 'button[data-cookies=\"allow_all_cookies\"]')\n",
    "                )\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", cookie_btn)\n",
    "            print(\"‚úÖ Cookies accepted\\n\")\n",
    "            cookie_handled = True\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# FUNCTION: Get first product link from listing page\n",
    "# ==============================\n",
    "def get_first_product_link(barcode):\n",
    "    try:\n",
    "        # Wait for either listing items to appear or \"no results\" message\n",
    "        time.sleep(2)  # Give page time to load results\n",
    "        \n",
    "        # Check if there are any results\n",
    "        listing_items = driver.find_elements(By.CSS_SELECTOR, \".listing-item__wrap\")\n",
    "        \n",
    "        if not listing_items:\n",
    "            print(f\"   ‚ö†Ô∏è  No products found for barcode: {barcode}\\n\")\n",
    "            return None\n",
    "        \n",
    "        # Get the first listing item\n",
    "        first_item = listing_items[0]\n",
    "        \n",
    "        # Get the product link from the title (try multiple selectors)\n",
    "        try:\n",
    "            title_link = first_item.find_element(By.CSS_SELECTOR, \".listing-item__name\")\n",
    "        except:\n",
    "            # Try alternative selector\n",
    "            title_link = first_item.find_element(By.CSS_SELECTOR, \"a.listing-item__name, [data-link]\")\n",
    "        \n",
    "        href = title_link.get_attribute(\"href\")\n",
    "        \n",
    "        # If href is not in the link element, check data-link attribute\n",
    "        if not href:\n",
    "            href = title_link.get_attribute(\"data-link\")\n",
    "        \n",
    "        # Remove fragment identifier (anything after #)\n",
    "        if href and \"#\" in href:\n",
    "            href = href.split(\"#\")[0]\n",
    "        \n",
    "        print(f\"   ‚úÖ Found first product for barcode: {barcode}\\n\")\n",
    "        return href\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Error getting product link: {str(e)[:100]}\\n\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# FUNCTION: Scrape product details from product page with images\n",
    "# ==============================\n",
    "def scrape_product_details_enhanced(product_url, barcode):\n",
    "    print(f\"      Scraping: {product_url}\")\n",
    "    \n",
    "    driver.get(product_url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Create sanitized barcode for folder name\n",
    "    sanitized_barcode = barcode.replace(\" \", \"_\").replace(\"/\", \"-\").replace(\"\\\\\", \"-\")\n",
    "    images_folder = f\"images/{sanitized_barcode}\"\n",
    "    \n",
    "    product_data = {\n",
    "        \"barcode\": barcode,\n",
    "        \"product_url\": product_url,\n",
    "        \"product_name\": \"\",\n",
    "        \"price\": \"\",\n",
    "        \"discount_percentage\": \"\",\n",
    "        \"vat_percentage\": \"\",\n",
    "        \"images_folder\": images_folder,\n",
    "        \"images_downloaded\": 0,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Extract product name from h1\n",
    "        try:\n",
    "            h1_element = driver.find_element(By.CSS_SELECTOR, \"h1.product-block__title\")\n",
    "            product_data[\"product_name\"] = h1_element.text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Extract price\n",
    "        try:\n",
    "            price_element = driver.find_element(By.CSS_SELECTOR, \".product-block__price-new, .listing-item__price-new\")\n",
    "            product_data[\"price\"] = price_element.text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Extract discount percentage\n",
    "        try:\n",
    "            discount_element = driver.find_element(By.CSS_SELECTOR, \".product-block__discount, .discount-percentage\")\n",
    "            product_data[\"discount_percentage\"] = discount_element.text.strip()\n",
    "        except:\n",
    "            product_data[\"discount_percentage\"] = \"N/A\"\n",
    "        \n",
    "        # Extract VAT percentage\n",
    "        try:\n",
    "            vat_element = driver.find_element(By.CSS_SELECTOR, \".product-block__inkl, .listing-item__inkl\")\n",
    "            vat_text = vat_element.text.strip()\n",
    "            import re\n",
    "            vat_match = re.search(r'(\\d+)%', vat_text)\n",
    "            if vat_match:\n",
    "                product_data[\"vat_percentage\"] = vat_match.group(1) + \"%\"\n",
    "            else:\n",
    "                product_data[\"vat_percentage\"] = vat_text\n",
    "        except:\n",
    "            product_data[\"vat_percentage\"] = \"N/A\"\n",
    "        \n",
    "        # Extract all description items dynamically\n",
    "        try:\n",
    "            description_items = driver.find_elements(By.CSS_SELECTOR, \".product-description__item\")\n",
    "            \n",
    "            for item in description_items:\n",
    "                try:\n",
    "                    title_elem = item.find_element(By.CSS_SELECTOR, \".product-description__item-title\")\n",
    "                    value_elem = item.find_element(By.CSS_SELECTOR, \".product-description__item-value\")\n",
    "                    \n",
    "                    title = title_elem.text.strip().replace(\":\", \"\").strip()\n",
    "                    value = value_elem.text.strip()\n",
    "                    \n",
    "                    # Create a sanitized column name\n",
    "                    column_name = title.replace(\" \", \"_\").replace(\"[\", \"\").replace(\"]\", \"\").lower()\n",
    "                    product_data[column_name] = value\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Download product images\n",
    "        os.makedirs(images_folder, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            thumbnail_images = driver.find_elements(By.CSS_SELECTOR, \".product-gallery__image-list-item img\")\n",
    "            image_urls = []\n",
    "            \n",
    "            for img_elem in thumbnail_images:\n",
    "                img_url = None\n",
    "                \n",
    "                # Try srcset first\n",
    "                srcset = img_elem.get_attribute(\"srcset\")\n",
    "                if srcset:\n",
    "                    parts = srcset.split(\",\")\n",
    "                    for part in reversed(parts):\n",
    "                        if \"2x\" in part or parts.index(part) == len(parts) - 1:\n",
    "                            img_url = part.split()[0].strip()\n",
    "                            break\n",
    "                \n",
    "                # Try data-srcset\n",
    "                if not img_url:\n",
    "                    data_srcset = img_elem.get_attribute(\"data-srcset\")\n",
    "                    if data_srcset:\n",
    "                        parts = data_srcset.split(\",\")\n",
    "                        for part in reversed(parts):\n",
    "                            if \"2x\" in part or parts.index(part) == len(parts) - 1:\n",
    "                                img_url = part.split()[0].strip()\n",
    "                                break\n",
    "                \n",
    "                # Last resort: src\n",
    "                if not img_url:\n",
    "                    img_url = img_elem.get_attribute(\"src\")\n",
    "                \n",
    "                if img_url and img_url.startswith(\"http\"):\n",
    "                    image_urls.append(img_url)\n",
    "            \n",
    "            # Download images\n",
    "            downloaded_count = 0\n",
    "            for idx, img_url in enumerate(image_urls, 1):\n",
    "                try:\n",
    "                    response = requests.get(img_url, timeout=10)\n",
    "                    if response.status_code == 200:\n",
    "                        ext = \".jpg\"\n",
    "                        if \".\" in img_url.split(\"/\")[-1]:\n",
    "                            url_filename = img_url.split(\"?\")[0].split(\"/\")[-1]\n",
    "                            if \".\" in url_filename:\n",
    "                                ext = \".\" + url_filename.split(\".\")[-1]\n",
    "                        \n",
    "                        filename = f\"{images_folder}/image_{idx}{ext}\"\n",
    "                        with open(filename, \"wb\") as f:\n",
    "                            f.write(response.content)\n",
    "                        downloaded_count += 1\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            product_data[\"images_downloaded\"] = downloaded_count\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"         ‚ö†Ô∏è  Error scraping product: {e}\")\n",
    "    \n",
    "    return product_data\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# MAIN LOOP: Process ALL barcodes\n",
    "# ==============================\n",
    "from openpyxl import Workbook\n",
    "\n",
    "print(\"\\nüöÄ Starting to process all barcodes...\\n\")\n",
    "\n",
    "for idx, code in enumerate(barcodes, 1):\n",
    "    print(f\"[{idx}/{len(barcodes)}] Processing barcode: {code}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    url = f\"https://www.autodoc.parts/search?keyword={code}\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "    handle_cookies()\n",
    "    \n",
    "    # Wait for page content to load\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Get first product link only\n",
    "    product_link = get_first_product_link(code)\n",
    "    \n",
    "    # Visit the product link and scrape details\n",
    "    if product_link:\n",
    "        product_data = scrape_product_details_enhanced(product_link, code)\n",
    "        all_product_data.append(product_data)\n",
    "        print(f\"   ‚úÖ Product scraped: {product_data.get('product_name', 'Unknown')[:50]}\")\n",
    "        print(f\"   üíæ Images: {product_data.get('images_downloaded', 0)} downloaded\")\n",
    "        print(f\"\\n‚úÖ Completed barcode {code}\\n\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  No product found for barcode {code}\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# SAVE TO EXCEL\n",
    "# ==============================\n",
    "if all_product_data:\n",
    "    output_file = \"all_products_scraped.xlsx\"\n",
    "    \n",
    "    # Collect all unique column names from all products\n",
    "    all_columns = set()\n",
    "    for product in all_product_data:\n",
    "        all_columns.update(product.keys())\n",
    "    \n",
    "    # Sort columns to have consistent order (base columns first)\n",
    "    base_columns = [\"barcode\", \"product_url\", \"product_name\", \"price\", \"discount_percentage\", \n",
    "                   \"vat_percentage\", \"images_folder\", \"images_downloaded\"]\n",
    "    other_columns = sorted([col for col in all_columns if col not in base_columns])\n",
    "    ordered_columns = base_columns + other_columns\n",
    "    \n",
    "    # Create Excel workbook\n",
    "    wb_output = Workbook()\n",
    "    ws = wb_output.active\n",
    "    ws.title = \"Products\"\n",
    "    \n",
    "    # Write headers\n",
    "    ws.append(ordered_columns)\n",
    "    \n",
    "    # Write data rows\n",
    "    for product in all_product_data:\n",
    "        row = [product.get(col, \"\") for col in ordered_columns]\n",
    "        ws.append(row)\n",
    "    \n",
    "    # Auto-adjust column widths\n",
    "    for column in ws.columns:\n",
    "        max_length = 0\n",
    "        column_letter = column[0].column_letter\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(str(cell.value))\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = min(max_length + 2, 50)\n",
    "        ws.column_dimensions[column_letter].width = adjusted_width\n",
    "    \n",
    "    wb_output.save(output_file)\n",
    "    \n",
    "    print(f\"\\n‚úÖ SCRAPING COMPLETE!\")\n",
    "    print(f\"   üìä Total products scraped: {len(all_product_data)}\")\n",
    "    print(f\"   üíæ Saved to: {output_file}\")\n",
    "    print(f\"   üìÅ Total columns: {len(ordered_columns)}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No products were scraped\")\n",
    "\n",
    "driver.quit()\n",
    "print(\"\\n‚úÖ All done! Browser closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaaefefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing browser...\n",
      "Testing with first barcode: 34356790304 SK\n",
      "============================================================\n",
      "‚úÖ Cookies accepted\n",
      "\n",
      "   ‚úÖ Found first product for barcode: 34356790304 SK\n",
      "\n",
      "   Visiting product page...\n",
      "   Found 9 description items\n",
      "\n",
      "   Downloading product images...\n",
      "   Found 5 images to download\n",
      "      ‚úÖ Downloaded image 1/5: images/34356790304_SK/image_1.jpg (121914 bytes)\n",
      "      ‚úÖ Downloaded image 2/5: images/34356790304_SK/image_2.jpg (34922 bytes)\n",
      "      ‚úÖ Downloaded image 3/5: images/34356790304_SK/image_3.jpg (90063 bytes)\n",
      "      ‚úÖ Downloaded image 4/5: images/34356790304_SK/image_4.jpg (67880 bytes)\n",
      "      ‚úÖ Downloaded image 5/5: images/34356790304_SK/image_5.jpg (67700 bytes)\n",
      "\n",
      "‚úÖ Product data extracted:\n",
      "   Product Name: RIDEX 407W0062 Brake pad wear sensor for BMW X3, X4\n",
      "Rear Axle\n",
      "   Price: ¬£7. 59\n",
      "   Discount: -42%\n",
      "   VAT: 20%\n",
      "   Images Folder: images/34356790304_SK\n",
      "   Images Downloaded: 5\n",
      "   Total fields extracted: 17\n",
      "\n",
      "‚úÖ Saved detailed test product to test_product_detailed.xlsx\n",
      "   Columns saved: ['barcode', 'product_url', 'product_name', 'price', 'discount_percentage', 'vat_percentage', 'images_folder', 'images_downloaded', 'fitting_position', 'brake_type', 'length_mm', 'weight_kg', 'item_number', 'manufacturer', 'ean_number', 'required_quantity', 'condition']\n",
      "============================================================\n",
      "‚úÖ Test complete. Browser closed.\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# TEST: Process FIRST barcode only - ENHANCED VERSION (Excel Output + Images)\n",
    "# ==============================\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# Reinitialize driver for testing - more robust cleanup\n",
    "print(\"Initializing browser...\")\n",
    "try:\n",
    "    driver.quit()\n",
    "    del driver\n",
    "    del wait\n",
    "except:\n",
    "    pass\n",
    "\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "driver = uc.Chrome(options=options)\n",
    "wait = WebDriverWait(driver, 15)\n",
    "cookie_handled = False\n",
    "\n",
    "test_barcode = barcodes[0]\n",
    "print(f\"Testing with first barcode: {test_barcode}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    url = f\"https://www.autodoc.co.uk/spares-search?keyword={test_barcode}\"\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "    handle_cookies()\n",
    "\n",
    "    # Wait for page content to load\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Get first product link\n",
    "    product_link = get_first_product_link(test_barcode)\n",
    "\n",
    "    # Visit the product link and scrape details\n",
    "    if product_link:\n",
    "        print(f\"   Visiting product page...\")\n",
    "        driver.get(product_link)\n",
    "        time.sleep(3)  # Give more time for product page to load\n",
    "        \n",
    "        # Create sanitized barcode for folder name\n",
    "        sanitized_barcode = test_barcode.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "        images_folder = f\"images/{sanitized_barcode}\"\n",
    "        \n",
    "        product_data = {\n",
    "            \"barcode\": test_barcode,\n",
    "            \"product_url\": product_link,\n",
    "            \"product_name\": \"\",\n",
    "            \"price\": \"\",\n",
    "            \"discount_percentage\": \"\",\n",
    "            \"vat_percentage\": \"\",\n",
    "            \"images_folder\": images_folder,\n",
    "            \"images_downloaded\": 0,\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Extract product name from h1\n",
    "            try:\n",
    "                h1_element = driver.find_element(By.CSS_SELECTOR, \"h1.product-block__title\")\n",
    "                product_data[\"product_name\"] = h1_element.text.strip()\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è  Could not find product name: {e}\")\n",
    "            \n",
    "            # Extract price\n",
    "            try:\n",
    "                price_element = driver.find_element(By.CSS_SELECTOR, \".product-block__price-new, .listing-item__price-new\")\n",
    "                product_data[\"price\"] = price_element.text.strip()\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è  Could not find price: {e}\")\n",
    "            \n",
    "            # Extract discount percentage\n",
    "            try:\n",
    "                discount_element = driver.find_element(By.CSS_SELECTOR, \".product-block__discount, .discount-percentage\")\n",
    "                product_data[\"discount_percentage\"] = discount_element.text.strip()\n",
    "            except:\n",
    "                product_data[\"discount_percentage\"] = \"N/A\"\n",
    "            \n",
    "            # Extract VAT percentage\n",
    "            try:\n",
    "                vat_element = driver.find_element(By.CSS_SELECTOR, \".product-block__inkl, .listing-item__inkl\")\n",
    "                vat_text = vat_element.text.strip()\n",
    "                # Try to extract percentage from text like \"price incl. 19% VAT\"\n",
    "                import re\n",
    "                vat_match = re.search(r'(\\d+)%', vat_text)\n",
    "                if vat_match:\n",
    "                    product_data[\"vat_percentage\"] = vat_match.group(1) + \"%\"\n",
    "                else:\n",
    "                    product_data[\"vat_percentage\"] = vat_text\n",
    "            except:\n",
    "                product_data[\"vat_percentage\"] = \"N/A\"\n",
    "            \n",
    "            # Extract all description items dynamically\n",
    "            try:\n",
    "                description_items = driver.find_elements(By.CSS_SELECTOR, \".product-description__item\")\n",
    "                print(f\"   Found {len(description_items)} description items\")\n",
    "                \n",
    "                for item in description_items:\n",
    "                    try:\n",
    "                        title_elem = item.find_element(By.CSS_SELECTOR, \".product-description__item-title\")\n",
    "                        value_elem = item.find_element(By.CSS_SELECTOR, \".product-description__item-value\")\n",
    "                        \n",
    "                        title = title_elem.text.strip().replace(\":\", \"\").strip()\n",
    "                        value = value_elem.text.strip()\n",
    "                        \n",
    "                        # Create a sanitized column name\n",
    "                        column_name = title.replace(\" \", \"_\").replace(\"[\", \"\").replace(\"]\", \"\").lower()\n",
    "                        product_data[column_name] = value\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è  Error extracting description items: {e}\")\n",
    "            \n",
    "            # Download product images\n",
    "            print(f\"\\n   Downloading product images...\")\n",
    "            \n",
    "            # Create folder for images\n",
    "            os.makedirs(images_folder, exist_ok=True)\n",
    "            \n",
    "            image_urls = []\n",
    "            try:\n",
    "                # Get all thumbnail images from the gallery\n",
    "                thumbnail_images = driver.find_elements(By.CSS_SELECTOR, \".product-gallery__image-list-item img\")\n",
    "                \n",
    "                for img_elem in thumbnail_images:\n",
    "                    # Try to get the highest resolution URL\n",
    "                    img_url = None\n",
    "                    \n",
    "                    # First try srcset (highest resolution)\n",
    "                    srcset = img_elem.get_attribute(\"srcset\")\n",
    "                    if srcset:\n",
    "                        # srcset format: \"url1 1x, url2 2x\"\n",
    "                        # Split by comma and get the 2x version (higher res)\n",
    "                        parts = srcset.split(\",\")\n",
    "                        for part in reversed(parts):  # Start from end to get 2x first\n",
    "                            if \"2x\" in part or parts.index(part) == len(parts) - 1:\n",
    "                                img_url = part.split()[0].strip()\n",
    "                                break\n",
    "                    \n",
    "                    # If no srcset, try data-srcset\n",
    "                    if not img_url:\n",
    "                        data_srcset = img_elem.get_attribute(\"data-srcset\")\n",
    "                        if data_srcset:\n",
    "                            parts = data_srcset.split(\",\")\n",
    "                            for part in reversed(parts):\n",
    "                                if \"2x\" in part or parts.index(part) == len(parts) - 1:\n",
    "                                    img_url = part.split()[0].strip()\n",
    "                                    break\n",
    "                    \n",
    "                    # Last resort: use src\n",
    "                    if not img_url:\n",
    "                        img_url = img_elem.get_attribute(\"src\")\n",
    "                    \n",
    "                    if img_url and img_url.startswith(\"http\"):\n",
    "                        image_urls.append(img_url)\n",
    "                \n",
    "                print(f\"   Found {len(image_urls)} images to download\")\n",
    "                \n",
    "                # Download each image\n",
    "                downloaded_images = []\n",
    "                for idx, img_url in enumerate(image_urls, 1):\n",
    "                    try:\n",
    "                        response = requests.get(img_url, timeout=10)\n",
    "                        if response.status_code == 200:\n",
    "                            # Get file extension from URL or default to .jpg\n",
    "                            ext = \".jpg\"\n",
    "                            if \".\" in img_url.split(\"/\")[-1]:\n",
    "                                url_filename = img_url.split(\"?\")[0].split(\"/\")[-1]\n",
    "                                if \".\" in url_filename:\n",
    "                                    ext = \".\" + url_filename.split(\".\")[-1]\n",
    "                            \n",
    "                            filename = f\"{images_folder}/image_{idx}{ext}\"\n",
    "                            with open(filename, \"wb\") as f:\n",
    "                                f.write(response.content)\n",
    "                            downloaded_images.append(filename)\n",
    "                            print(f\"      ‚úÖ Downloaded image {idx}/{len(image_urls)}: {filename} ({len(response.content)} bytes)\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"      ‚ö†Ô∏è  Failed to download image {idx}: {e}\")\n",
    "                \n",
    "                # Update the count\n",
    "                product_data[\"images_downloaded\"] = len(downloaded_images)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è  Error downloading images: {e}\")\n",
    "            \n",
    "            print(\"\\n‚úÖ Product data extracted:\")\n",
    "            print(f\"   Product Name: {product_data['product_name']}\")\n",
    "            print(f\"   Price: {product_data['price']}\")\n",
    "            print(f\"   Discount: {product_data['discount_percentage']}\")\n",
    "            print(f\"   VAT: {product_data['vat_percentage']}\")\n",
    "            print(f\"   Images Folder: {product_data['images_folder']}\")\n",
    "            print(f\"   Images Downloaded: {product_data.get('images_downloaded', 0)}\")\n",
    "            print(f\"   Total fields extracted: {len(product_data)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Error scraping product: {e}\")\n",
    "        \n",
    "        # Save to Excel\n",
    "        test_output = \"test_product_detailed.xlsx\"\n",
    "        wb_output = Workbook()\n",
    "        ws = wb_output.active\n",
    "        ws.title = \"Product Data\"\n",
    "        \n",
    "        # Write headers\n",
    "        headers = list(product_data.keys())\n",
    "        ws.append(headers)\n",
    "        \n",
    "        # Write data\n",
    "        ws.append(list(product_data.values()))\n",
    "        \n",
    "        # Auto-adjust column widths\n",
    "        for column in ws.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 2, 50)  # Cap at 50 characters\n",
    "            ws.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        wb_output.save(test_output)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Saved detailed test product to {test_output}\")\n",
    "        print(f\"   Columns saved: {list(product_data.keys())}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  No product found for barcode {test_barcode}\")\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Test failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    # Close driver after test\n",
    "    try:\n",
    "        driver.quit()\n",
    "        print(\"‚úÖ Test complete. Browser closed.\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è  Browser was already closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
